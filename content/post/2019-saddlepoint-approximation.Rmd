---
title: "Approximate densities for sums of variables: Negative Binomials and saddlepoint"
date: 2019-04-24
tags: ["R","Stan","Modelling"]
draft: true
---

I recently needed to find the distribution of sum of non-identical negative binomial (NB) random variables. Although for some special cases the [sum is itself NB - TODO link](), analytical solution is not feasible in the general case. However it turns out there is a very handy tool called "Saddlepoint approximation" that is useful whenever you need densities of sums of arbitrary random variables. In this post I use the sum of NBs as a case study on how to derive your own approximations for basically any sum of random variables, show some tricks needed to get the approximation working in Stan and evaluate it against simpler approximations. To give credit where credit is due, I was introduced to the saddlepoint method via [Cross Validated answer on sum of Gamma variables](https://stats.stackexchange.com/questions/72479/generic-sum-of-gamma-random-variables/137318#137318).

# The approximation - big picture
The saddlepoint approximation uses the [cumulant-generating function](https://en.wikipedia.org/wiki/Cumulant) (CGF) of a distribution to compute an approximate density at a given point. The neat part about CGFs is that the CGF of the sum of several variables is the sum of the individual CGFs! And CGFs are easy to come by, because the CGF is just the log of the moment-generating function and Wikipedia helpfully lists moment-generating functions for almost all distributions. Figuring out the CGF of almost any sum variable is thus straightforward. 

The actual method for approximating density $f$ at point $x$, given the cumulant-generating function $K$, and its first and second derivatives ($K^\prime,K^{\prime\prime}$) is as follows:

1) find the saddlepoint $s_x$ by solving:

$$
$$

Generally, there is no closed-form solution for $s_x$, but since $K(x)$ is always convex, $K^\prime$ is always increasing, making it a nice target for numerical solutions. Still, since a different solution is needed for each $x$, finding $s$ tends to be a computational bottleneck.

2) Once we have $s_x$, we can approximate

$$
f(x) \simeq
$$

In the above equation, we can add further terms with higher derivatives of $K$ (see e.g. [TODO link] for a general formula), but for the cases I was concerned with, the first two terms are enough.

The nice thing about the saddlepoint approximation is that it can easily produce approximations for both discrete and continous densities, and doesn't constrain the approximation to be normal or of any other family (unlike Laplace approximation).

# Saddlepoint for sum of NBs

Given the above.

It turns out that the saddlepoint is not defined when $x = 0$, but for this special case, the density can be easily computed, as $f(0) = \prod_i P(X_i =0) = \prod_i  NB(0 | \mu_i,\phi_i)$. The non-existance of the saddlepoint solution for boundaries of the domain is actually a recurring theme, so it is useful to check for this when developing your approximations.


# Worked out saddlepoint approximations for other families

- Sum of Gamma variables: [Answer on Cross Validated](https://stats.stackexchange.com/questions/72479/generic-sum-of-gamma-random-variables/137318#137318)
- Sum of binomials: [Liu & Quertermous: Approximating the Sum of Independent Non-Identical Binomial Random Variables](https://arxiv.org/abs/1712.01410)

# Simpler alternatives



```{r setup, message=FALSE, warning=FALSE}
library(rstan)
library(knitr)
library(here)
library(tidyverse)
library(cowplot)
library(rstanmodeldev)
options(mc.cores = parallel::detectCores())
rstan_options(auto_write = TRUE)
set.seed(24683068)
```

dd

```{r}
model_file <- here("static","2019-saddlepoint-approximation.stan","test_sum_nb.stan")
model_sum_nb <- stan_model(model_file)
```

Generating data

```{r}
generator <- function(G, N, method = "saddlepoint", prior_mean_mus = 2, prior_sd_mus = 1) {
  if(method == "saddlepoint") {
    method_id = 0
  } else if (method == "moments") {
    method_id = 1
  } else {
    stop("Invalid method")
  }
  
  function() {
    all_mus <- rlnorm(G + 1, prior_mean_mus, prior_sd_mus)
    all_mus[G + 1] <- rlnorm(1, 5, 3)
    all_phis <- 1 / sqrt(abs(rnorm(G + 1)))
    sums <- array(-1, N)
    repeats <- 0
    for(n in 1:N) {
      repeat {
        sums[n] <- sum(rnbinom(G + 1, mu = all_mus, size = all_phis))
        if(sums[n] > 0) {
          break;
        } 
        repeats <- repeats + 1
      }
    }
    if(repeats > 0) {
      cat(repeats, " repeats\n")
    }
    list(
      observed = list(
        N = N,
        sums = sums,
        G = G,
        method = method_id,
        mus = array(all_mus[1:G], G),
        phis = array(all_phis[1:G], G)
        #phis = all_phis
      ),
      true = list(
        extra_mu = all_mus[G+1],
        extra_phi = all_phis[G+1]
      )
    )
  }
}
```

Testing a single version to see it doesn't break terribly.

```{r}
data <- generator(G = 5, N = 5, "moments")()
fit <- sampling(model_sum_nb, data$observed)
evaluate_all_params(rstan::extract(fit), data$true)
```

# Sum of two NBs

Here we test a sum of two NBs - one is small and has known parameters, the other has unknown parameters and possibly larger mean (the prior mean is larger).

Calibration and accuracy with saddlepoint approximation

```{r}
sbc_res_saddlepoint_small <- sbc(model_sum_nb, generator(G = 1, N = 10, "saddlepoint"), N_steps = 100, control = list(adapt_delta = 0.95))
plot_sbc_params(sbc_res_saddlepoint_small$params, x_axis_trans = "log10", y_axis_trans = "log10")
summarise_sbc_diagnostics(sbc_res_saddlepoint_small)

```

Median time - saddlepoint small, individual: 52.7035

Calibration and accuracy with moments approximation

```{r}
sbc_res_moments_small <- sbc(model_sum_nb, generator(G = 1, N = 10, "moments"), N_steps = 100, control = list(adapt_delta = 0.95))
plot_sbc_params(sbc_res_moments_small$params, x_axis_trans = "log10", y_axis_trans = "log10")
summarise_sbc_diagnostics(sbc_res_moments_small)

```

# Sum of 21 NBs

20 NBs are known (low means) and one NB is unknown (a prior large mean)

Saddlepoint:

```{r}
sbc_res_saddlepoint_large <- sbc(model_sum_nb, generator(G = 20, N = 20, "saddlepoint"), N_steps = 100, control = list(adapt_delta = 0.95))
plot_sbc_params(sbc_res_saddlepoint_large$params, x_axis_trans = "log10", y_axis_trans = "log10")
summarise_sbc_diagnostics(sbc_res_saddlepoint_large)

```

Median time - saddlepoint large, individual: 259.2945

Moments:

```{r}
sbc_res_moments_large <- sbc(model_sum_nb, generator(G = 20, N = 20, "moments"), N_steps = 100, control = list(adapt_delta = 0.95))
plot_sbc_params(sbc_res_moments_large$params, x_axis_trans = "log10", y_axis_trans = "log10", plot_stat = "mean")
summarise_sbc_diagnostics(sbc_res_moments_large)

```

# 10 large NBs

9 known NBs, 1 unknown, all large ($log(\mu) \sim N(5,3)$). Here, the estimates start to be dominated by the prior.

Saddlepoint:
```{r}
sbc_res_saddlepoint_10_large <- sbc(model_sum_nb, generator(G = 9, N = 10, "saddlepoint", prior_mean_mus = 5, prior_sd_mus = 3), N_steps = 100, control = list(adapt_delta = 0.95))
plot_sbc_params(sbc_res_saddlepoint_10_large$params, x_axis_trans = "log10", y_axis_trans = "log10")
summarise_sbc_diagnostics(sbc_res_saddlepoint_10_large)
```


Moments:
```{r}
sbc_res_moments_10_large <- sbc(model_sum_nb, generator(G = 9, N = 10, "moments", prior_mean_mus = 5, prior_sd_mus = 3), N_steps = 100, control = list(adapt_delta = 0.95))
plot_sbc_params(sbc_res_moments_10_large$params, x_axis_trans = "log10", y_axis_trans = "log10")
summarise_sbc_diagnostics(sbc_res_moments_10_large)
```

